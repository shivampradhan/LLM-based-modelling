# LLM-based-modelling

# NLP Notebooks

![NLP](https://www.upwork.com/catalog-images/c0717a4a34e39d0ff4391b01b6898cd1)

## Pretraining

* BERT Mask Language Modeling | Pretraining[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Ankur3107/colab_notebooks/blob/master/pretraining/Bert_Pre_Training.ipynb)

## Classification

* BERT Classification in Pytorch[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Ankur3107/colab_notebooks/blob/master/classification/Bert_Classification_Pt.ipynb)

* BERT Sentence Classification 2 in Pytorch[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Ankur3107/colab_notebooks/blob/master/classification/BERT_Fine_Tuning_Sentence_Classification_v2.ipynb)

* Generic Class for Classification using transformers[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Ankur3107/colab_notebooks/blob/master/classification/Generic_Transformer_Classification.ipynb)

* Large Scale Multi Label Classification[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Ankur3107/colab_notebooks/blob/master/classification/large_scale_multilabelclassification.ipynb)

## Question Answering

* Question Answering with a Fine Tuned BERT [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Ankur3107/colab_notebooks/blob/master/question-answering/Question_Answering_with_a_Fine_Tuned_BERT.ipynb)


## Machine Translation

* Machine Translation using transformers [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Ankur3107/colab_notebooks/blob/master/machine-translation/Seq2Seq_Pytorch.ipynb)


## Topic Modeling

* Contextual Topic Modeling [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Ankur3107/colab_notebooks/blob/master/topic-modeling/contextual_topic_modeling.ipynb)


## Knowledge Distillation

* BERT Knowledge Distillation in LSTM [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Ankur3107/colab_notebooks/blob/master/knowledge-distillation/knowledge_distillation_exploration.ipynb)


## NLP Package Exploration

* Simpletransformers Exploration [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Ankur3107/colab_notebooks/blob/master/nlp-package-exploration/Simpletransformers_2.ipynb)

* Fastai + Transformers Exploration [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Ankur3107/colab_notebooks/blob/master/nlp-package-exploration/Using_Transformers_with_Fastai_Tutorial.ipynb)

## Diffusion
|No|Title|Open in Studio Lab|Open in Kaggle|Open in Colab|
|---|---|---|---|---|
|1|[Deconstruct the Stable Diffusion pipeline](diffusion/diffusers/deconstruct_the_stable_diffusion_pipline.ipynb)|[![Open in SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/hololandscape/notebooks/blob/main/diffusion/diffusers/deconstruct_the_stable_diffusion_pipline.ipynb)|[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/hololandscape/notebooks/blob/main/diffusion/diffusers/deconstruct_the_stable_diffusion_pipline.ipynb)|[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/hololandscape/notebooks/blob/main/diffusion/diffusers/deconstruct_the_stable_diffusion_pipline.ipynb)|
|2|[Basic training model](diffusion/diffusers/basic_training_model.ipynb)||[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/hololandscape/notebooks/blob/main/diffusion/diffusers/basic_training_model.ipynb)|[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/hololandscape/notebooks/blob/main/diffusion/diffusers/basic_training_model.ipynb)|
|3|[Deconstruct the basic pipeline](diffusion/diffusers/deconstruct_basic_pipeline.ipynb)||[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/hololandscape/notebooks/blob/main/diffusion/diffusers/deconstruct_basic_pipeline.ipynb)||
|4|[Details for models and schedulers](diffusion/diffusers/details_for_models_scheduler.ipynb)||[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/hololandscape/notebooks/blob/main/diffusion/diffusers/details_for_models_scheduler.ipynb)||
|5|[Effective and Efficient diffusion](diffusion/diffusers/effective_and_efficient_diffusion.ipynb)||[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/hololandscape/notebooks/blob/main/diffusion/diffusers/effective_and_efficient_diffusion.ipynb)||
|6|[Generting by using float16(sppeding up)](diffusion/diffusers/generating_by_fp16.ipynb)||[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/hololandscape/notebooks/blob/main/diffusion/diffusers/generating_by_fp16.ipynb)||
|7|[Stable Diffusion v1.5 demo](diffusion/diffusers/stable_diffusion_v1_5_demo.ipynb)||[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/hololandscape/notebooks/blob/main/diffusion/diffusers/stable_diffusion_v1_5_demo.ipynb)||
|8|[Load checkpoints models and schedulers](diffusion/diffusers/load_checkpoints_models_schedulers.ipynb)||[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/hololandscape/notebooks/blob/main/diffusion/diffusers/load_checkpoints_models_schedulers.ipynb)||
|9|[Schedulers Performance](diffusion/diffusers/schedulers_performance.ipynb)||[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/hololandscape/notebooks/blob/main/diffusion/diffusers/schedulers_performance.ipynb)||
|10|[Stable diffusion with diffusers](diffusion/diffusers/stable_diffusion_with_diffusers.ipynb)||[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/hololandscape/notebooks/blob/main/diffusion/diffusers/stable_diffusion_with_diffusers.ipynb)||

## Implementation
|No|Title|Open in Studio Lab|Open in Kaggle|Open in Colab|Paper|
|---|---|---|---|---|---|
|1|[The annotated diffusion model](implementation/the_annotated_diffusion_model.ipynb)||[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/hololandscape/notebooks/blob/main/implementation/the_annotated_diffusion_model.ipynb)||[1503.03585](https://arxiv.org/abs/1503.03585),[1907.05600](https://arxiv.org/abs/1907.05600),[2006.11239](https://arxiv.org/abs/2006.11239)|
|2|[QLoRA Fine-tuning for Falcon-7B with PEFT](implementation/qlora_for_ft_falcon_7b.ipynb)||Being reviewed|||


## PyTorch Fundamentals

* [Basic programming with PyTorch](pytorch/README.md)
* [Computer vision with PyTorch](pytorch/computer_vision/README.md)
* [Natural language processing with PyTorch](pytorch/natural_language_processing/README.md)
* [Audio classification with PyTorch](pytorch/audio_classification/README.md)



## On Kaggle

Many of the notebooks are executed on Kaggle

|No|Title|Open in Kaggle|
|---|---|---|
|1|Segment Anything Model|[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://www.kaggle.com/code/aisuko/segment-anything-model)|
|2|CTransformers|[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://www.kaggle.com/code/aisuko/ctransformers)|


## On macOS

All the notebooks are support [mps](https://aisuko.gitbook.io/wiki/ai-techniques/large-language-model/metal), except if the notebooks import fp16 speeding up:

* [The kernel crashed](https://github.com/microsoft/vscode-jupyter/issues/13828)

![mps](images/image.png)

# Transformers Notebooks

This repository contains the example code from our O'Reilly book [Natural Language Processing with Transformers](https://www.oreilly.com/library/view/natural-language-processing/9781098136789/):

<img alt="book-cover" height=200 src="images/book_cover.jpg" id="book-cover"/>

## Getting started

You can run these notebooks on cloud platforms like [Google Colab](https://colab.research.google.com/) or your local machine. Note that most chapters require a GPU to run in a reasonable amount of time, so we recommend one of the cloud platforms as they come pre-installed with CUDA.

### Running on a cloud platform

To run these notebooks on a cloud platform, just click on one of the badges in the table below:

<!--This table is automatically generated, do not fill manually!-->



| Chapter                                     | Colab                                                                                                                                                                                               | Kaggle                                                                                                                                                                                                   | Gradient                                                                                                                                                                               | Studio Lab                                                                                                                                                                                                   |
|:--------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Introduction                                | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nlp-with-transformers/notebooks/blob/main/01_introduction.ipynb)              | [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/nlp-with-transformers/notebooks/blob/main/01_introduction.ipynb)              | [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://console.paperspace.com/github/nlp-with-transformers/notebooks/blob/main/01_introduction.ipynb)              | [![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/nlp-with-transformers/notebooks/blob/main/01_introduction.ipynb)              |
| Text Classification                         | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nlp-with-transformers/notebooks/blob/main/02_classification.ipynb)            | [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/nlp-with-transformers/notebooks/blob/main/02_classification.ipynb)            | [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://console.paperspace.com/github/nlp-with-transformers/notebooks/blob/main/02_classification.ipynb)            | [![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/nlp-with-transformers/notebooks/blob/main/02_classification.ipynb)            |
| Transformer Anatomy                         | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nlp-with-transformers/notebooks/blob/main/03_transformer-anatomy.ipynb)       | [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/nlp-with-transformers/notebooks/blob/main/03_transformer-anatomy.ipynb)       | [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://console.paperspace.com/github/nlp-with-transformers/notebooks/blob/main/03_transformer-anatomy.ipynb)       | [![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/nlp-with-transformers/notebooks/blob/main/03_transformer-anatomy.ipynb)       |
| Multilingual Named Entity Recognition       | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nlp-with-transformers/notebooks/blob/main/04_multilingual-ner.ipynb)          | [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/nlp-with-transformers/notebooks/blob/main/04_multilingual-ner.ipynb)          | [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://console.paperspace.com/github/nlp-with-transformers/notebooks/blob/main/04_multilingual-ner.ipynb)          | [![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/nlp-with-transformers/notebooks/blob/main/04_multilingual-ner.ipynb)          |
| Text Generation                             | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nlp-with-transformers/notebooks/blob/main/05_text-generation.ipynb)           | [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/nlp-with-transformers/notebooks/blob/main/05_text-generation.ipynb)           | [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://console.paperspace.com/github/nlp-with-transformers/notebooks/blob/main/05_text-generation.ipynb)           | [![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/nlp-with-transformers/notebooks/blob/main/05_text-generation.ipynb)           |
| Summarization                               | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nlp-with-transformers/notebooks/blob/main/06_summarization.ipynb)             | [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/nlp-with-transformers/notebooks/blob/main/06_summarization.ipynb)             | [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://console.paperspace.com/github/nlp-with-transformers/notebooks/blob/main/06_summarization.ipynb)             | [![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/nlp-with-transformers/notebooks/blob/main/06_summarization.ipynb)             |
| Question Answering                          | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nlp-with-transformers/notebooks/blob/main/07_question-answering.ipynb)        | [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/nlp-with-transformers/notebooks/blob/main/07_question-answering.ipynb)        | [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://console.paperspace.com/github/nlp-with-transformers/notebooks/blob/main/07_question-answering.ipynb)        | [![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/nlp-with-transformers/notebooks/blob/main/07_question-answering.ipynb)        |
| Making Transformers Efficient in Production | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nlp-with-transformers/notebooks/blob/main/08_model-compression.ipynb)         | [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/nlp-with-transformers/notebooks/blob/main/08_model-compression.ipynb)         | [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://console.paperspace.com/github/nlp-with-transformers/notebooks/blob/main/08_model-compression.ipynb)         | [![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/nlp-with-transformers/notebooks/blob/main/08_model-compression.ipynb)         |
| Dealing with Few to No Labels               | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nlp-with-transformers/notebooks/blob/main/09_few-to-no-labels.ipynb)          | [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/nlp-with-transformers/notebooks/blob/main/09_few-to-no-labels.ipynb)          | [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://console.paperspace.com/github/nlp-with-transformers/notebooks/blob/main/09_few-to-no-labels.ipynb)          | [![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/nlp-with-transformers/notebooks/blob/main/09_few-to-no-labels.ipynb)          |
| Training Transformers from Scratch          | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nlp-with-transformers/notebooks/blob/main/10_transformers-from-scratch.ipynb) | [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/nlp-with-transformers/notebooks/blob/main/10_transformers-from-scratch.ipynb) | [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://console.paperspace.com/github/nlp-with-transformers/notebooks/blob/main/10_transformers-from-scratch.ipynb) | [![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/nlp-with-transformers/notebooks/blob/main/10_transformers-from-scratch.ipynb) |
| Future Directions                           | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nlp-with-transformers/notebooks/blob/main/11_future-directions.ipynb)         | [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/nlp-with-transformers/notebooks/blob/main/11_future-directions.ipynb)         | [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://console.paperspace.com/github/nlp-with-transformers/notebooks/blob/main/11_future-directions.ipynb)         | [![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/nlp-with-transformers/notebooks/blob/main/11_future-directions.ipynb)         |

<!--End of table-->


Posts ordered by most recent publishing date

    Hitting Time Forecasting: The Other Way for Time Series Probabilistic Forecasting [post]|[code]
    Forecasting with Granger Causality: Checking for Time Series Spurious Correlations [post]|[code]
    Hacking Causal Inference: Synthetic Control with ML approaches [post]|[code]
    Model Selection with Imbalance Data: Only AUC may Not Save you [post]|[code]
    PCA for Multivariate Time Series: Forecasting Dynamic High-Dimensional Data [post]|[code]
    Hacking Statistical Significance: Hypothesis Testing with ML Approaches [post]|[code]
    Time Series Forecasting with Conformal Prediction Intervals: Scikit-Learn is All you Need [post]|[code]
    Rethinking Survival Analysis: How to Make your Model Produce Survival Curves [post]|[code]
    Extreme Churn Prediction: Forecasting Without Features [post]|[code]
    Forecast Time Series with Missing Values: Beyond Linear Interpolation [post]|[code]
    Forecasting Uncertainty with Linear Models like in Deep Learning [post]|[code]
    Time Series Forecasting with Feature Selection: Why you may need it [post]|[code]
    Anomaly Detection in Multivariate Time Series with Network Graphs [post]|[code]
    How to Improve Recursive Time Series Forecasting [post]|[code]
    Retrain, or not Retrain? Online Machine Learning with Gradient Boosting [post]|[code]
    Data Drift Explainability: Interpretable Shift Detection with NannyML [post]|[code]
    Word2Vec with Time Series: A Transfer Learning Approach [post]|[code]
    SHAP for Drift Detection: Effective Data Shift Monitoring [post]|[code]
    Forecasting with Trees: Hybrid Classifiers for Time Series [post]|[code]
    Boruta SHAP for Temporal Feature Selection [post]|[code]
    Forecasting with Trees: Hybrid Modeling for Time Series [post]|[code]
    Recursive Feature Selection: Addition or Elimination? [post]|[code]
    Improve Random Forest with Linear Models [post]|[code]
    Is Gradient Boosting good as Prophet for Time Series Forecasting? [post]|[code]
    Linear Boosting with Automated Features Engineering [post]|[code]
    Improve Linear Regression for Time Series Forecasting [post]|[code]
    Boruta and SHAP for better Feature Selection [post]|[code]
    Explainable AI with Linear Trees [post]|[code]
    SHAP for Feature Selection and HyperParameter Tuning [post]|[code]
    Model Tree: handle Data Shifts mixing Linear Model and Decision Tree [post]|[code]
    Add Prediction Intervals to your Forecasting Model [post]|[code]
    Linear Tree: the perfect mix of Linear Model and Decision Tree [post]
    ARIMA for Classification with Soft Labels [post]|[code]
    Advanced Permutation Importance to Explain Predictions [post]|[code]
    Time Series Bootstrap in the age of Deep Learning [post]|[code]
    Anomaly Detection with Extreme Value Analysis [post]|[code]
    Time Series generation with VAE LSTM [post]|[code]
    Extreme Event Time Series Preprocessing [post]|[code]
    One-Class Neural Network in Keras [post]|[code]
    Real-Time Time Series Anomaly Detection [post]|[code]
    Entropy Application in the Stock Market [post]|[code]
    Time Series Smoothing for better Forecasting [post]|[code]
    Time Series Smoothing for better Clustering [post]|[code]
    Predictive Maintenance with ResNet [post]|[code]
    Neural Networks Ensemble [post]|[code]
    Anomaly Detection in Multivariate Time Series with VAR [post]|[code]
    Corr2Vec: a WaveNet architecture for Feature Engineering in Financial Market [post]|[code]
    Siamese and Dual BERT for Multi Text Classification [post]|[code]
    Time Series Forecasting with Graph Convolutional Neural Network [post]|[code]
    Neural Network Calibration with Keras [post]|[code]
    Combine LSTM and VAR for Multivariate Time Series Forecasting [post]|[code]
    Feature Importance with Time Series and Recurrent Neural Network [post]|[code]
    Group2Vec for Advance Categorical Encoding [post]|[code]
    Survival Analysis with Deep Learning in Keras [post]|[code]
    Survival Analysis with LightGBM plus Poisson Regression [post]|[code]
    Predictive Maintenance: detect Faults from Sensors with CRNN and Spectrograms [post]|[code]
    Multi-Sample Dropout in Keras [post]|[code]
    When your Neural Net doesnâ€™t know: a bayesian approach with Keras [post]|[code]
    Dynamic Meta Embeddings in Keras [post]|[code]
    Predictive Maintenance with LSTM Siamese Network [post]|[code]
    Text Data Augmentation makes your model stronger [post]|[code]
    Anomaly Detection with Permutation Undersampling and Time Dependency [post]|[code]
    Time2Vec for Time Series features encoding [post]|[code]
    Automate Data Cleaning with Unsupervised Learning [post]|[code]
    People Tracking with Machine Learning [post]|[code]
    Time Series Clustering and Dimensionality Reduction [post]|[code]
    Anomaly Detection in Images [post]|[code]
    Feature Importance with Neural Network [post]|[code]
    Anomaly Detection with LSTM in Keras [post]|[code]
    Dress Segmentation with Autoencoder in Keras [post]|[code]
    Extreme Event Forecasting with LSTM Autoencoders [post]|[code]
    Zalando Dress Recommendation and Tagging [post]|[code]
    Remaining Life Estimation with Keras [post]|[code]
    Quality Control with Machine Learning [post]|[code]
    Predictive Maintenance: detect Faults from Sensors with CNN [post]|[code]

# Companion Jupyter notebooks for the book "Deep Learning with Python"

This repository contains Jupyter notebooks implementing the code samples found in the book [Deep Learning with Python, 2nd Edition (Manning Publications)](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff).

For readability, these notebooks only contain runnable code blocks and section titles, and omit everything else in the book: text paragraphs, figures, and pseudocode.
**If you want to be able to follow what's going on, I recommend reading the notebooks side by side with your copy of the book.**

These notebooks use TensorFlow 2.6.

## Table of contents

* [Chapter 2: The mathematical building blocks of neural networks](https://colab.research.google.com/github/fchollet/deep-learning-with-python-notebooks/blob/master/chapter02_mathematical-building-blocks.ipynb)
* [Chapter 3: Introduction to Keras and TensorFlow](https://colab.research.google.com/github/fchollet/deep-learning-with-python-notebooks/blob/master/chapter03_introduction-to-keras-and-tf.ipynb)
* [Chapter 4: Getting started with neural networks: classification and regression](https://colab.research.google.com/github/fchollet/deep-learning-with-python-notebooks/blob/master/chapter04_getting-started-with-neural-networks.ipynb)
* [Chapter 5: Fundamentals of machine learning](https://colab.research.google.com/github/fchollet/deep-learning-with-python-notebooks/blob/master/chapter05_fundamentals-of-ml.ipynb)
* [Chapter 7: Working with Keras: a deep dive](https://colab.research.google.com/github/fchollet/deep-learning-with-python-notebooks/blob/master/chapter07_working-with-keras.ipynb)
* [Chapter 8: Introduction to deep learning for computer vision](https://colab.research.google.com/github/fchollet/deep-learning-with-python-notebooks/blob/master/chapter08_intro-to-dl-for-computer-vision.ipynb)
* Chapter 9: Advanced deep learning for computer vision
    - [Part 1: Image segmentation](https://colab.research.google.com/github/fchollet/deep-learning-with-python-notebooks/blob/master/chapter09_part01_image-segmentation.ipynb)
    - [Part 2: Modern convnet architecture patterns](https://colab.research.google.com/github/fchollet/deep-learning-with-python-notebooks/blob/master/chapter09_part02_modern-convnet-architecture-patterns.ipynb)
    - [Part 3: Interpreting what convnets learn](https://colab.research.google.com/github/fchollet/deep-learning-with-python-notebooks/blob/master/chapter09_part03_interpreting-what-convnets-learn.ipynb)
* [Chapter 10: Deep learning for timeseries](https://colab.research.google.com/github/fchollet/deep-learning-with-python-notebooks/blob/master/chapter10_dl-for-timeseries.ipynb)
* Chapter 11: Deep learning for text
    - [Part 1: Introduction](https://colab.research.google.com/github/fchollet/deep-learning-with-python-notebooks/blob/master/chapter11_part01_introduction.ipynb)
    - [Part 2: Sequence models](https://colab.research.google.com/github/fchollet/deep-learning-with-python-notebooks/blob/master/chapter11_part02_sequence-models.ipynb)
    - [Part 3: Transformer](https://colab.research.google.com/github/fchollet/deep-learning-with-python-notebooks/blob/master/chapter11_part03_transformer.ipynb)
    - [Part 4: Sequence-to-sequence learning](https://colab.research.google.com/github/fchollet/deep-learning-with-python-notebooks/blob/master/chapter11_part04_sequence-to-sequence-learning.ipynb)
* Chapter 12: Generative deep learning
    - [Part 1: Text generation](https://colab.research.google.com/github/fchollet/deep-learning-with-python-notebooks/blob/master/chapter12_part01_text-generation.ipynb)
    - [Part 2: Deep Dream](https://colab.research.google.com/github/fchollet/deep-learning-with-python-notebooks/blob/master/chapter12_part02_deep-dream.ipynb)
    - [Part 3: Neural style transfer](https://colab.research.google.com/github/fchollet/deep-learning-with-python-notebooks/blob/master/chapter12_part03_neural-style-transfer.ipynb)
    - [Part 4: Variational autoencoders](https://colab.research.google.com/github/fchollet/deep-learning-with-python-notebooks/blob/master/chapter12_part04_variational-autoencoders.ipynb)
    - [Part 5: Generative adversarial networks](https://colab.research.google.com/github/fchollet/deep-learning-with-python-notebooks/blob/master/chapter12_part05_gans.ipynb)
* [Chapter 13: Best practices for the real world](https://colab.research.google.com/github/fchollet/deep-learning-with-python-notebooks/blob/master/chapter13_best-practices-for-the-real-world.ipynb)
* [Chapter 14: Conclusions](https://colab.research.google.com/github/fchollet/deep-learning-with-python-notebooks/blob/master/chapter14_conclusions.ipynb)

The whole book can be read using the links below. Each part contains a notebook that you can find in this repository.

    Getting Started with PyTorch
    Build Your First Neural Network
    Transfer Learning for Image Classification using Torchvision
    Face Detection on Custom Dataset with Detectron2
    Time Series Forecasting with LSTMs for Daily Coronavirus Cases
    Time Series Anomaly Detection using LSTM Autoencoders
    Create Dataset for Sentiment Analysis by Scraping Google Play App Reviews
    Sentiment Analysis with BERT and Transformers by Hugging Face
    Deploy BERT for Sentiment Analysis as REST API using FastAPI
    Object Detection on Custom Dataset with YOLO (v5)


## Contributing

Warm welcome for any contributions, please follow the [contributing guidelines](CONTRIBUTING.md).

## Credit
- [Huggingface diffusers](https://github.com/huggingface/diffusers)
- [Microsoft learning](https://learn.microsoft.com/en-au/training/modules/intro-machine-learning-pytorch/)


